{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "\n",
    "## Assignment - UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install segmentation_models --quiet\n",
    "%pip install comet_ml --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comet Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.com https://www.comet.com/mamello-justice/cv-deep/83761ba811af4689bea27e4e58de9884\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "experiment = Experiment(project_name = \"cv-deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv_gmm_deep'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegmentation_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Unet\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcv_gmm_deep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcv_gmm_deep\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_data, preprocess_data\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv_gmm_deep'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.models import load_model\n",
    "from segmentation_models import Unet\n",
    "\n",
    "from cv_gmm_deep.datasets import load_data\n",
    "from cv_gmm_deep.common import split_data, preprocess_data\n",
    "\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"tensorflow=={tf.__version__}\")\n",
    "print(f\"keras=={keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'vgg16'\n",
    "\n",
    "assets_dir = './assets'\n",
    "data_dir = './data'\n",
    "\n",
    "default_input_size = [768, 1024]\n",
    "default_input_dir = path.join(\n",
    "    assets_dir,\n",
    "    f'puzzle_corners_{default_input_size[1]}x{default_input_size[0]}')\n",
    "\n",
    "time_now = int(time.time())\n",
    "\n",
    "default_cp_path = path.join(data_dir, str(time_now), 'cp.ckpt')\n",
    "default_model_path = path.join(data_dir, str(time_now), 'model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'augmented': True,\n",
    "    'batch_size': 2,\n",
    "    'epochs': 2,\n",
    "    'input_size': default_input_size,\n",
    "}\n",
    "\n",
    "experiment.log_parameters(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_args():\n",
    "    return {\n",
    "        'cp_path': default_cp_path,\n",
    "        'input_dir': default_input_dir,\n",
    "        'model_path': default_model_path,\n",
    "        'update_model': None,\n",
    "        'cpu': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = setup_args()\n",
    "\n",
    "use_cpu = args['cpu']\n",
    "if use_cpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "augmented = params['augmented']\n",
    "batch_size = params['batch_size']\n",
    "epochs = params['epochs']\n",
    "input_size = params['input_size']\n",
    "\n",
    "cp_path = args['cp_path']\n",
    "input_dir = args['input_dir']\n",
    "model_path = args['model_path']\n",
    "update_model = args['update_model']\n",
    "\n",
    "height, width = input_size\n",
    "\n",
    "raw_x, raw_y = load_data(input_dir, height, width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = preprocess_data(raw_x, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (val_x, val_y), (test_x, test_y) =\\\n",
    "    split_data(data_x, data_y)\n",
    "    \n",
    "experiment.log_dataset_hash(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = callbacks.ModelCheckpoint(filepath=cp_path,\n",
    "                                          save_weights_only=True,\n",
    "                                          verbose=1)\n",
    "\n",
    "if update_model and model_path:\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    model = Unet(BACKBONE,\n",
    "                 encoder_weights='imagenet',\n",
    "                 input_shape=(*input_size, 3))\n",
    "    \n",
    "assert model is not None, \"Could not load model\"\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(val_x, val_y),\n",
    "          callbacks=[checkpoint_cb])\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comet Commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14a7046b3493b92b1d842fb1e941b2babd846baed7e15e3a50bd6e259b71f0cc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 ('cv_gmm_deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
